# MCP Agent Chat API

TechnickÃ¡ dokumentace pro FastAPI backend systÃ©m MCP Agenta.

## ğŸ—ï¸ PÅ™ehled architektury

Toto API poskytuje konverzaÄnÃ­ rozhranÃ­ pro MCP (Model Context Protocol) agenta, kterÃ½ mÅ¯Å¾e interagovat s externÃ­mi nÃ¡stroji (jako je Notion). SystÃ©m je postaven na architektuÅ™e zaloÅ¾enÃ© na session, kterÃ¡ udrÅ¾uje historii konverzace napÅ™Ã­Ä vÃ­ce poÅ¾adavky.

### KlÃ­ÄovÃ© komponenty

1. **FastAPI Server** ([`src/api.py`](../src/api.py)) - HTTP/WebSocket endpointy
2. **Agent Core** ([`src/lib/agent_core.py`](../src/lib/agent_core.py)) - Logika agenta a sprÃ¡va session
3. **MCP Integration** - Orchestrace nÃ¡strojÅ¯ prostÅ™ednictvÃ­m Model Context Protocol
4. **LangChain** - Abstrakce LLM a pamÄ›Å¥ konverzace

### Tok poÅ¾adavku/odpovÄ›di

```
Client Request
    â†“
FastAPI Endpoint (REST/WebSocket/SSE)
    â†“
AgentService.run_query()
    â†“
Session Management (retrieve/create session)
    â†“
MCPAgent.run() - LLM + MCP Tools
    â†“
Update Session History & Memory
    â†“
Response to Client
```

## ğŸ§  Design agentnÃ­ho systÃ©mu

### Architektura zaloÅ¾enÃ¡ na sessions

**ProÄ architektura zaloÅ¾enÃ¡ na sessions?**
- **ZachovÃ¡nÃ­ kontextu**: KaÅ¾dÃ½ uÅ¾ivatel udrÅ¾uje vlastnÃ­ historii konverzace
- **Podpora vÃ­ce uÅ¾ivatelÅ¯**: RÅ¯znÃ­ uÅ¾ivatelÃ© mohou vÃ©st nezÃ¡vislÃ© konverzace
- **StavovÃ© interakce**: Agent si pamatuje pÅ™edchozÃ­ vÃ½mÄ›ny v rÃ¡mci session

SystÃ©m pouÅ¾Ã­vÃ¡ slovnÃ­k sessions (`sessions: Dict[str, Dict[str, Any]]`), kterÃ½ uklÃ¡dÃ¡:
- `memory`: instanci [`ConversationBufferMemory`](../src/lib/agent_core.py:67) pro integraci s LangChain
- `history`: Seznam objektÅ¯ zprÃ¡v pro API odpovÄ›di

**PoznÃ¡mka pro produkci**: ÃšloÅ¾iÅ¡tÄ› session v pamÄ›ti by mÄ›lo bÃ½t v produkÄnÃ­m prostÅ™edÃ­ nahrazeno Redis nebo databÃ¡zÃ­ pro podporu horizontÃ¡lnÃ­ho Å¡kÃ¡lovÃ¡nÃ­ a persistence.

### PamÄ›Å¥ konverzace

**ProÄ ConversationBufferMemory?**

SystÃ©m pouÅ¾Ã­vÃ¡ [`ConversationBufferMemory`](../src/lib/agent_core.py:67) z LangChain s `return_messages=True`:

- **JednoduchÃ© a efektivnÃ­**: UklÃ¡dÃ¡ kompletnÃ­ historii konverzace bez sumarizace
- **PlnÃ½ kontext**: LLM mÃ¡ pÅ™Ã­stup k celÃ© konverzaci pro lepÅ¡Ã­ porozumÄ›nÃ­
- **SnadnÃ¡ integrace**: BezproblÃ©movÄ› funguje s agentnÃ­m systÃ©mem LangChain
- **FlexibilnÃ­**: SnadnÃ© rozÅ¡Ã­Å™enÃ­ o jinÃ© typy pamÄ›ti (summary, window, atd.)

**Kompromisy**:
- âœ… PerfektnÃ­ zapamatovÃ¡nÃ­ kontextu konverzace
- âœ… Å½Ã¡dnÃ¡ ztrÃ¡ta informacÃ­ ze sumarizace
- âŒ SpotÅ™eba tokenÅ¯ roste s dÃ©lkou konverzace
- âŒ MÅ¯Å¾e dosÃ¡hnout limitÅ¯ kontextu u velmi dlouhÃ½ch konverzacÃ­

Pro produkci zvaÅ¾te [`ConversationBufferWindowMemory`](https://python.langchain.com/docs/modules/memory/types/buffer_window) pro efektivnÄ›jÅ¡Ã­ vyuÅ¾itÃ­ tokenÅ¯ nebo [`ConversationSummaryMemory`](https://python.langchain.com/docs/modules/memory/types/summary) pro velmi dlouhÃ© konverzace.

### Å½ivotnÃ­ cyklus agenta

**ProÄ vytvÃ¡Å™et novÃ©ho agenta pro kaÅ¾dÃ½ poÅ¾adavek?**

V [`AgentService.run_query()`](../src/lib/agent_core.py:81) je pro kaÅ¾dÃ½ dotaz vytvoÅ™ena novÃ¡ instance [`MCPAgent`](../src/lib/agent_core.py:81):

```python
agent = MCPAgent(llm=self.llm, client=self.client, max_steps=30)
result = await agent.run(message)
```

**ZdÅ¯vodnÄ›nÃ­**:
- **BezstavovÃ½ agent**: KaÅ¾dÃ© spuÅ¡tÄ›nÃ­ agenta je nezÃ¡vislÃ©, zabraÅˆuje Ãºniku stavu
- **BezpeÄnost vlÃ¡ken**: Å½Ã¡dnÃ½ sdÃ­lenÃ½ mÄ›nitelnÃ½ stav mezi soubÄ›Å¾nÃ½mi poÅ¾adavky
- **ÄŒistÃ© provedenÃ­**: ÄŒerstvÃ½ stav agenta zajiÅ¡Å¥uje pÅ™edvÃ­datelnÃ© chovÃ¡nÃ­
- **PamÄ›Å¥ v session**: Kontext konverzace je zachovÃ¡n v objektu session, ne v agentovi

PamÄ›Å¥ session je potÃ© aktualizovÃ¡na po kaÅ¾dÃ©m ÃºspÄ›Å¡nÃ©m spuÅ¡tÄ›nÃ­ pro zachovÃ¡nÃ­ kontinuity.

## ğŸ”§ TechnologickÃ½ stack

### HlavnÃ­ knihovny

| Knihovna | Verze | ÃšÄel | ProÄ tato volba? |
|---------|---------|---------|------------------|
| **FastAPI** | Latest | Web framework | ModernÃ­ asynchronnÃ­ podpora, automatickÃ© OpenAPI dokumenty, typovÃ¡ bezpeÄnost |
| **LangChain** | 0.3.27 | LLM orchestrace | PrÅ¯myslovÃ½ standard pro agentnÃ­ workflow, rozsÃ¡hlÃ© integrace |
| **LangChain-OpenAI** | 0.3.34 | OpenAI LLM wrapper | JednotnÃ© rozhranÃ­ pro OpenAI-kompatibilnÃ­ API |
| **MCP** | 1.16.0 | Model Context Protocol | StandardizovanÃ½ protokol pro integraci nÃ¡strojÅ¯ |
| **mcp-use** | 1.3.11 | MCP agent implementace | VysokoÃºrovÅˆovÃ¡ abstrakce agenta nad MCP |
| **Uvicorn** | 0.37.0 | ASGI server | ProdukÄnÄ› pÅ™ipravenÃ½ asynchronnÃ­ server pro FastAPI |
| **python-dotenv** | 1.1.1 | Konfigurace prostÅ™edÃ­ | BezpeÄnÃ¡ sprÃ¡va API klÃ­ÄÅ¯ |

### LLM poskytovatel: OpenRouter

SystÃ©m pouÅ¾Ã­vÃ¡ [**OpenRouter**](https://openrouter.ai) jako poskytovatele LLM:

```python
llm = ChatOpenAI(
    model="google/gemini-2.5-flash-lite-preview-09-2025",
    openai_api_base="https://openrouter.ai/api/v1",
    openai_api_key=OPENROUTER_API_KEY,
    temperature=0,
)
```

**ProÄ OpenRouter?**
- **JednotnÃ© API**: PÅ™Ã­stup k vÃ­ce poskytovatelÅ¯m LLM (OpenAI, Anthropic, Google, atd.) pÅ™es jedno rozhranÃ­
- **Flexibilita modelÅ¯**: SnadnÃ© pÅ™epÃ­nÃ¡nÃ­ mezi modely bez zmÄ›n kÃ³du
- **Optimalizace nÃ¡kladÅ¯**: VÃ½bÄ›r nÃ¡kladovÄ› efektivnÃ­ch modelÅ¯ podle poÅ¾adavkÅ¯ Ãºlohy
- **MoÅ¾nosti fallbacku**: Lze implementovat automatickÃ½ fallback na alternativnÃ­ modely
- **KompatibilnÃ­ s OpenAI**: Funguje s wrapperem `ChatOpenAI` z LangChain

**AktuÃ¡lnÃ­ model**: `google/gemini-2.5-flash-lite-preview-09-2025`
- RychlÃ© doby odezvy
- NÃ¡kladovÄ› efektivnÃ­ pro konverzaÄnÃ­ Ãºlohy
- DobrÃ¡ rovnovÃ¡ha mezi schopnostmi a rychlostÃ­

### MCP (Model Context Protocol)

**Co je MCP?**
MCP je protokol, kterÃ½ umoÅ¾Åˆuje LLM interagovat s externÃ­mi nÃ¡stroji a datovÃ½mi zdroji standardizovanÃ½m zpÅ¯sobem.

**AktuÃ¡lnÃ­ konfigurace**:
```python
config = {
    "mcpServers": {
        "Notion": {
            "url": "https://mcp.notion.com/mcp"
        }
    }
}
```

**ProÄ MCP?**
- **StandardizovanÃ© volÃ¡nÃ­ nÃ¡strojÅ¯**: KonzistentnÃ­ rozhranÃ­ pro rÅ¯znÃ© nÃ¡stroje
- **AutomatickÃ© zjiÅ¡Å¥ovÃ¡nÃ­**: NÃ¡stroje vystavujÃ­ svÃ© schopnosti pomocÃ­ protokolu
- **TypovÃ¡ bezpeÄnost**: StrukturovanÃ¡ validace vstupu/vÃ½stupu
- **RozÅ¡iÅ™itelnÃ©**: SnadnÃ© pÅ™idÃ¡vÃ¡nÃ­ novÃ½ch integracÃ­ nÃ¡strojÅ¯

## ğŸ“¡ API Endpointy

### 1. REST API - `/api/chat` (POST)

**NejlepÅ¡Ã­ pro**: JednoduchÃ© interakce poÅ¾adavek/odpovÄ›Ä, nenÃ­ potÅ™eba streaming

**PoÅ¾adavek**:
```json
{
  "message": "Create a new Notion page called 'Meeting Notes'",
  "session_id": "user-123"
}
```

**OdpovÄ›Ä**:
```json
{
  "response": "I've created a new page titled 'Meeting Notes' in your Notion workspace.",
  "session_id": "user-123"
}
```

**Implementace**: [`src/api.py:29-32`](../src/api.py:29-32)

**PÅ™Ã­klad**:
```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "What tasks do I have?", "session_id": "user-123"}'
```

### 2. WebSocket - `/ws/chat`

**NejlepÅ¡Ã­ pro**: Real-time obousmÄ›rnÃ¡ komunikace, interaktivnÃ­ chatovÃ© aplikace

**PÅ™ipojenÃ­ klienta**:
```javascript
const ws = new WebSocket('ws://localhost:8000/ws/chat');

ws.onopen = () => {
  ws.send(JSON.stringify({
    message: "List my Notion pages",
    session_id: "user-123"
  }));
};

ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  console.log(data);
};
```

**Typy zprÃ¡v**:
- `status`: Notifikace o zpracovÃ¡nÃ­
- `response`: OdpovÄ›Ä agenta (s `done: true`)
- `error`: ChybovÃ¡ zprÃ¡va

**Implementace**: [`src/api.py:35-73`](../src/api.py:35-73)

**ProÄ WebSocket?**
- PerzistentnÃ­ pÅ™ipojenÃ­ sniÅ¾uje latenci
- UmoÅ¾Åˆuje indikÃ¡tory psanÃ­ a aktualizace prÅ¯bÄ›hu
- SkuteÄnÄ› obousmÄ›rnÃ¡ komunikace
- LepÅ¡Ã­ pro chatovÃ¡ rozhranÃ­

### 3. Server-Sent Events - `/api/chat/stream` (GET)

**NejlepÅ¡Ã­ pro**: JednosmÄ›rnÃ½ streaming ze serveru na klienta

**PoÅ¾adavek**:
```bash
curl -N http://localhost:8000/api/chat/stream?message=Hello
```

**Stream odpovÄ›di**:
```
data: {"type": "status", "message": "Processing..."}

data: {"type": "response", "message": "Hi! How can I help?", "done": true}
```

**Implementace**: [`src/api.py:76-102`](../src/api.py:76-102)

**JavaScript pÅ™Ã­klad**:
```javascript
const eventSource = new EventSource(
  'http://localhost:8000/api/chat/stream?message=Hello'
);

eventSource.onmessage = (event) => {
  const data = JSON.parse(event.data);
  console.log(data);
};
```

**ProÄ SSE?**
- JednoduÅ¡Å¡Ã­ neÅ¾ WebSocket pro jednosmÄ›rnÃ½ streaming
- Funguje pÅ™es standardnÃ­ HTTP
- AutomatickÃ¡ podpora opÄ›tovnÃ©ho pÅ™ipojenÃ­
- LepÅ¡Ã­ kompatibilita s firewallem

### 4. PomocnÃ© endpointy

**Health Check** - `GET /health`
```json
{"status": "healthy"}
```

**Root** - `GET /`
```json
{"message": "MCP Agent API is running"}
```

## ğŸš€ SpuÅ¡tÄ›nÃ­ API

### PÅ™edpoklady

1. **Python 3.8+**
2. **PromÄ›nnÃ© prostÅ™edÃ­**:
   ```bash
   # .env soubor
   OPENROUTER_API_KEY=your_api_key_here
   ```

### Instalace

```bash
# Instalace zÃ¡vislostÃ­
pip install -r requirements.txt
```

### SpuÅ¡tÄ›nÃ­ serveru

**ZÃ¡kladnÃ­ spuÅ¡tÄ›nÃ­**:
```bash
python main.py
```

**S moÅ¾nostmi**:
```bash
# VlastnÃ­ port
python main.py --port 8080

# ZapnutÃ­ auto-reload pro vÃ½voj
python main.py --reload

# Debug logovÃ¡nÃ­
python main.py --log-level debug

# VlastnÃ­ host (produkce)
python main.py --host 0.0.0.0 --port 8000
```

**PromÄ›nnÃ© prostÅ™edÃ­**:
```bash
export API_HOST=0.0.0.0
export API_PORT=8080
export RELOAD=true
export LOG_LEVEL=debug
python main.py
```

### ProdukÄnÃ­ nasazenÃ­

**PouÅ¾itÃ­ Gunicorn**:
```bash
pip install gunicorn
gunicorn -w 4 -k uvicorn.workers.UvicornWorker src.api:app --bind 0.0.0.0:8000
```

**Docker**:
```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
CMD ["python", "main.py"]
```

## ğŸ§ª TestovÃ¡nÃ­

### ManuÃ¡lnÃ­ testovÃ¡nÃ­

**REST API**:
```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello", "session_id": "test-1"}'
```

**WebSocket** (pouÅ¾itÃ­ `websocat`):
```bash
websocat ws://localhost:8000/ws/chat
# PotÃ© odeslat: {"message": "Hello", "session_id": "test-1"}
```

### AutomatizovanÃ© testovÃ¡nÃ­

SpuÅ¡tÄ›nÃ­ testovacÃ­ho skriptu konverzace:
```bash
python test/api_conversation_test.py
```

Tento skript ([`test/api_conversation_test.py`](../test/api_conversation_test.py)) demonstruje:
- VÃ­cetahovÃ© konverzace
- SprÃ¡vu session
- ZachovÃ¡nÃ­ kontextu napÅ™Ã­Ä poÅ¾adavky

### API dokumentace

FastAPI automaticky generuje interaktivnÃ­ API dokumentaci:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## ğŸ”’ BezpeÄnostnÃ­ aspekty

### AktuÃ¡lnÃ­ implementace
- CORS povolen pro localhost:3000 a localhost:3001
- NenÃ­ implementovÃ¡na autentizace

### DoporuÄenÃ­ pro produkci

1. **Autentizace pomocÃ­ API klÃ­Äe**:
```python
from fastapi import Security, HTTPException
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials

security = HTTPBearer()

async def verify_token(credentials: HTTPAuthorizationCredentials = Security(security)):
    if credentials.credentials != "your-secret-key":
        raise HTTPException(status_code=401, detail="Invalid token")
    return credentials.credentials
```

2. **Rate Limiting**:
```bash
pip install slowapi
```

3. **Pouze HTTPS** v produkci
4. **CORS podle prostÅ™edÃ­**:
```python
allow_origins = os.getenv("CORS_ORIGINS", "").split(",")
```

## ğŸ¯ Souhrn nÃ¡vrhovÃ½ch rozhodnutÃ­

| RozhodnutÃ­ | ZdÅ¯vodnÄ›nÃ­ |
|----------|-----------|
| **Architektura zaloÅ¾enÃ¡ na sessions** | UdrÅ¾uje kontext konverzace pro kaÅ¾dÃ©ho uÅ¾ivatele |
| **ConversationBufferMemory** | JednoduchÃ¡, kompletnÃ­ historie pro lepÅ¡Ã­ kontext |
| **NovÃ½ agent pro kaÅ¾dÃ½ poÅ¾adavek** | BezpeÄnÃ© pro vlÃ¡kna, bezstavovÃ© provÃ¡dÄ›nÃ­ |
| **OpenRouter** | FlexibilnÃ­ poskytovatel LLM s vÃ­ce moÅ¾nostmi modelÅ¯ |
| **VÃ­ce typÅ¯ endpointÅ¯** | Podpora rÅ¯znÃ½ch klientskÃ½ch architektur (REST/WS/SSE) |
| **Sessions v pamÄ›ti** | JednoduchÃ© pro vÃ½voj; nahradit Redis pro produkci |
| **FastAPI** | ModernÃ­ asynchronnÃ­ framework s vynikajÃ­cÃ­ vÃ½vojÃ¡Å™skou zkuÅ¡enostÃ­ |
| **MCP protokol** | StandardizovanÃ¡ integrace nÃ¡strojÅ¯ |

## ğŸ“š Struktura kÃ³du

```
.
â”œâ”€â”€ main.py                      # VstupnÃ­ bod s CLI moÅ¾nostmi
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api.py                   # FastAPI endpointy
â”‚   â””â”€â”€ lib/
â”‚       â””â”€â”€ agent_core.py        # Logika agenta a sprÃ¡va session
â”œâ”€â”€ test/
â”‚   â””â”€â”€ api_conversation_test.py # Skript pro testovÃ¡nÃ­ konverzace
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ README_API.md           # Tento soubor
â””â”€â”€ requirements.txt            # Python zÃ¡vislosti
```

## ğŸ”„ RozÅ¡iÅ™ovÃ¡nÃ­ systÃ©mu

### PÅ™idÃ¡nÃ­ novÃ½ch MCP nÃ¡strojÅ¯

Upravit [`agent_core.py`](../src/lib/agent_core.py:39-45):
```python
config = {
    "mcpServers": {
        "Notion": {"url": "https://mcp.notion.com/mcp"},
        "GitHub": {"url": "https://github-mcp.example.com/mcp"}
    }
}
```

### ZmÄ›na LLM modelu

Upravit [`agent_core.py`](../src/lib/agent_core.py:31-36):
```python
self.llm = ChatOpenAI(
    model="anthropic/claude-3.5-sonnet",  # ZmÄ›nit model
    openai_api_base="https://openrouter.ai/api/v1",
    openai_api_key=OPENROUTER_API_KEY,
    temperature=0.7,  # Upravit kreativitu
)
```

### Implementace perzistentnÃ­ch sessions

Nahradit ÃºloÅ¾iÅ¡tÄ› v pamÄ›ti Redis:
```python
import redis
import json

redis_client = redis.Redis(host='localhost', port=6379, db=0)

def get_session(session_id: str):
    data = redis_client.get(f"session:{session_id}")
    return json.loads(data) if data else None

def save_session(session_id: str, session_data: dict):
    redis_client.set(f"session:{session_id}", json.dumps(session_data))
```

## ğŸ“Š Aspekty vÃ½konu

- **Max Steps**: Agent mÃ¡ `max_steps=30` pro prevenci nekoneÄnÃ½ch smyÄek
- **Temperature**: Nastavena na `0` pro deterministickÃ© odpovÄ›di
- **SoubÄ›Å¾nÃ© poÅ¾adavky**: FastAPI efektivnÄ› zpracovÃ¡vÃ¡ soubÄ›Å¾nÃ© poÅ¾adavky
- **RÅ¯st pamÄ›ti**: Sledovat ÃºloÅ¾iÅ¡tÄ› sessions, implementovat ÄiÅ¡tÄ›nÃ­ starÃ½ch sessions

## ğŸ› Å˜eÅ¡enÃ­ problÃ©mÅ¯

**Agent neodpovÃ­dÃ¡**:
- Zkontrolujte `OPENROUTER_API_KEY` v `.env`
- OvÄ›Å™te, Å¾e URL MCP serverÅ¯ jsou pÅ™Ã­stupnÃ©
- Zkontrolujte logy pro podrobnÃ© chybovÃ© zprÃ¡vy

**Session se neuchovÃ¡vÃ¡**:
- Sessions jsou v pamÄ›ti; restart je vymaÅ¾e
- Implementujte Redis pro perzistenci

**CORS chyby**:
- PÅ™idejte URL vaÅ¡eho frontendu do `allow_origins` v [`api.py`](../src/api.py:18)

## ğŸ“ DalÅ¡Ã­ zdroje

- [FastAPI dokumentace](https://fastapi.tiangolo.com/)
- [LangChain dokumentace](https://python.langchain.com/)
- [Model Context Protocol](https://modelcontextprotocol.io/)
- [OpenRouter dokumentace](https://openrouter.ai/docs)
